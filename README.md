# Translation API

A powerful multilingual translation service built with FastAPI and Groq using the Llama 3.1 70B model. This API provides high-quality translations powered by Groq's cloud infrastructure.

## Key Features

- **AI Translation** - Powered by Groq with Llama 3.1 70B model
- **100+ Languages** - Comprehensive language support
- **Auto Language Detection** - Automatically detects source language
- **Fallback Support** - Basic translation when Groq is unavailable
- **Fast & Efficient** - Built with FastAPI for high performance
- **Cloud-Powered** - Leverages Groq's high-performance infrastructure
- **High Quality** - Llama 3.1 70B provides excellent translation quality

## Project Structure

```
Saayam-Translate/
‚îú‚îÄ‚îÄ main.py                    # Main FastAPI application
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ test_groq_connection.py   # Groq connection test
‚îú‚îÄ‚îÄ test_translate.py         # Translation API test
‚îú‚îÄ‚îÄ start_translation_api.py  # API startup script
‚îú‚îÄ‚îÄ quick_start_groq.sh       # Quick start script
‚îú‚îÄ‚îÄ curl_examples.sh          # cURL examples for testing
‚îú‚îÄ‚îÄ README.md                 # This file
‚îú‚îÄ‚îÄ .gitignore               # Git ignore rules
‚îî‚îÄ‚îÄ Flow Diagrams/           # Project flow diagrams
```

## Quick Start

### Prerequisites
- Python 3.8+
- Groq API key
- Internet connection

### Step 1: Get Groq API Key
1. Sign up at [Groq Console](https://console.groq.com/)
2. Get your API key from the dashboard
3. Replace "XXX" in the following files with your actual API key:
   - `main.py` (line with `GROQ_API_KEY`)
   - `test_groq_connection.py` (both occurrences)
   - `start_translation_api.py` (line with `api_key`)

### Step 2: Create and Activate Conda Environment
```bash
# Create conda environment
conda create -n translate python=3.9

# Activate conda environment
conda activate translate
```

### Step 3: Install Python Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Test Groq Connection
```bash
python test_groq_connection.py
```

### Step 5: Run the Translation API
```bash
python main.py
```

### Step 6: Test the API
```bash
python test_translate.py
```

## API Reference

### Base URL
```
http://localhost:8000
```

### Endpoints

#### 1. Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "message": "Translation API is running. Groq status: running"
}
```

#### 2. Translate Text
```http
POST /translate
```

**Request Body:**
```json
{
  "text": "Hello, how are you?",
  "source_language": "English",  // Optional - auto-detected if not provided
  "target_language": "Spanish"   // Optional - defaults to "English"
}
```

**Response:**
```json
{
  "original_text": "Hello, how are you?",
  "translated_text": "Hola, ¬øc√≥mo est√°s?",
  "detected_language": "English",
  "source_language": "English",
  "target_language": "Spanish",
  "confidence": 0.95,
  "fallback_used": false,
  "message": "Translation completed successfully using Groq with Llama 3.1 70B"
}
```

#### 3. Detect Language
```http
POST /detect-language
```

**Request Body:**
```json
{
  "text": "Bonjour le monde"
}
```

**Response:**
```json
{
  "text": "Bonjour le monde",
  "detected_language": "French"
}
```

#### 4. Get Supported Languages
```http
GET /supported-languages
```

**Response:**
```json
[
  "English", "Spanish", "French", "German", "Italian", 
  "Portuguese", "Russian", "Japanese", "Korean", "Chinese",
  // ... 100+ languages
]
```

#### 5. Check Groq Status
```http
GET /groq-status
```

**Response:**
```json
{
  "groq_available": true,
  "model": "llama3-70b-8192",
  "status": "running"
}
```

## Usage Examples

### Python
```python
import requests

# Translate text
response = requests.post("http://localhost:8000/translate", json={
    "text": "Hello world",
    "target_language": "Spanish"
})
result = response.json()
print(f"Translated: {result['translated_text']}")

# Detect language
response = requests.post("http://localhost:8000/detect-language", json={
    "text": "Hola mundo"
})
result = response.json()
print(f"Detected language: {result['detected_language']}")

# Check API status
response = requests.get("http://localhost:8000/health")
print(response.json())
```

### cURL
```bash
# Translate text
curl -X POST "http://localhost:8000/translate" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world", "target_language": "Spanish"}'

# Detect language
curl -X POST "http://localhost:8000/detect-language" \
  -H "Content-Type: application/json" \
  -d '{"text": "Bonjour le monde"}'

# Get supported languages
curl -X GET "http://localhost:8000/supported-languages"

# Check Groq status
curl -X GET "http://localhost:8000/groq-status"
```

### JavaScript
```javascript
// Translate text
const response = await fetch('http://localhost:8000/translate', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    text: 'Hello world',
    target_language: 'Spanish'
  })
});

const result = await response.json();
console.log(`Translated: ${result.translated_text}`);
```

## Configuration

### Groq Settings
Modify the configuration in `main.py`:

```python
# Groq configuration
GROQ_API_KEY = "XXX"  # Replace with your actual API key
GROQ_MODEL = "llama3-70b-8192"  # Llama 3.1 70B model
```

### Using Different Models
You can use different models available in Groq:

```python
# Available models in Groq
GROQ_MODEL = "llama3-70b-8192"    # Llama 3.1 70B (current)
GROQ_MODEL = "llama3-8b-8192"     # Llama 3.1 8B
GROQ_MODEL = "mixtral-8x7b-32768" # Mixtral 8x7B
GROQ_MODEL = "gemma-7b-it"        # Gemma 7B
```

### Performance Tuning
Adjust translation parameters in `main.py`:

```python
response = groq_client.chat.completions.create(
    model=GROQ_MODEL,
    messages=[{"role": "user", "content": prompt}],
    max_tokens=500,        # Maximum response length
    temperature=0.1,       # Lower = more consistent, Higher = more creative
    top_p=0.9             # Nucleus sampling parameter
)
```

## üåç Supported Languages

The API supports **100+ languages** including:

### Major Languages
- **English**, **Spanish**, **French**, **German**, **Italian**
- **Portuguese**, **Russian**, **Japanese**, **Korean**, **Chinese**
- **Arabic**, **Hindi**, **Bengali**, **Urdu**, **Turkish**

### European Languages
- **Dutch**, **Swedish**, **Danish**, **Norwegian**, **Finnish**
- **Polish**, **Czech**, **Slovak**, **Hungarian**, **Romanian**
- **Bulgarian**, **Croatian**, **Serbian**, **Slovenian**, **Greek**

### Asian Languages
- **Thai**, **Vietnamese**, **Indonesian**, **Malay**, **Filipino**
- **Hindi**, **Bengali**, **Urdu**, **Persian**, **Hebrew**

### African Languages
- **Swahili**, **Afrikaans**, **Amharic**, **Somali**, **Hausa**
- **Yoruba**, **Igbo**, **Zulu**, **Xhosa**

## üîß Troubleshooting

### Common Issues

#### 1. Groq Service Not Available
**Error:** `"groq_available": false`

**Solution:**
```bash
# Check your API key
python test_groq_connection.py

# Ensure you have internet connection
curl https://api.groq.com/openai/v1/models
```

#### 2. API Key Invalid
**Error:** `Authentication failed`

**Solution:**
```bash
# Replace "XXX" with your actual API key in these files:
# - main.py
# - test_groq_connection.py  
# - start_translation_api.py

# Test connection
python test_groq_connection.py
```

#### 3. Port Already in Use
**Error:** `address already in use`

**Solution:**
```bash
# Find process using port 8000
lsof -i :8000

# Kill the process
kill <PID>

# Or use a different port in main.py
uvicorn.run(app, host="0.0.0.0", port=8001)
```

#### 4. Slow Translation
**Solution:**
- Check your internet connection
- Ensure Groq service is responding
- Consider using smaller models for faster responses
- Adjust temperature settings

### Performance Optimization

#### For Faster Responses:
```python
# Use smaller model
GROQ_MODEL = "llama3-8b-8192"

# Lower temperature for consistency
"temperature": 0.05
```

#### For Better Quality:
```python
# Use larger model (current)
GROQ_MODEL = "llama3-70b-8192"

# Higher temperature for creativity
"temperature": 0.2
```

## Performance Metrics

- **Translation Speed**: 1-3 seconds per translation
- **Memory Usage**: Minimal (cloud-based processing)
- **Quality**: High-quality translations with Llama 3.1 70B
- **Throughput**: 20-50 translations per minute
- **Availability**: 99.9% uptime with Groq infrastructure

## Security & Privacy

- **Secure API Calls**: All communication with Groq is encrypted
- **No Data Logging**: No translation data is stored locally
- **API Key Security**: API key should be replaced with your actual key before use
- **Cloud Infrastructure**: Leverages Groq's secure infrastructure
- **Open Source**: Transparent and auditable code

### ‚ö†Ô∏è Important Security Note
Before using this API, make sure to:
1. Replace all instances of "XXX" with your actual Groq API key
2. Never commit your API key to version control
3. Consider using environment variables for production deployments

## API Documentation

Once the server is running, access the interactive documentation:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

### Interactive API Documentation
Visit **http://localhost:8000/docs** in your browser to access the interactive Swagger UI documentation. This provides:
- Complete API endpoint documentation
- Interactive testing interface
- Request/response examples
- Schema definitions
- Try-it-out functionality for all endpoints

## Testing

### Run All Tests
```bash
python test_translate.py
```

### Test Groq Connection
```bash
python test_groq_connection.py
```

### Manual Testing
```bash
# Test translation
curl -X POST "http://localhost:8000/translate" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world", "target_language": "Spanish"}'

# Test health
curl http://localhost:8000/health
```

## Contributing

We welcome contributions! Here's how you can help:

### Areas for Improvement
- **Add more Groq models** (Mixtral, Gemma, etc.)
- **Improve translation prompts** for better quality
- **Add new language detection methods**
- **Enhance error handling** and logging
- **Add rate limiting** and caching
- **Create Docker support** for easy deployment

### Development Setup
```bash
# Clone the repository
git clone <your-repo-url>
cd Translation

# Install dependencies
pip install -r requirements.txt

# Install development dependencies
pip install pytest black flake8

# Run tests
python test_translate.py

# Format code
black main.py test_translate.py
```

## License

This project is open source and available under the [MIT License](LICENSE).

## Acknowledgments

- **Groq** - For providing the high-performance cloud infrastructure
- **Meta** - For the excellent Llama 3.1 70B model
- **FastAPI** - For the high-performance web framework
- **Open Source Community** - For various supporting libraries

## Support

If you encounter any issues:

1. **Check the troubleshooting section** above
2. **Review the API documentation** at http://localhost:8000/docs
3. **Test Groq connection** with `python test_groq_connection.py`
4. **Open an issue** on the project repository

---

**Happy Translating!‚ú®**
